{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fergus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fergus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "database_name = \"myDisasterDatabase.db\"\n",
    "output_model_file = \"disaster_model\"\n",
    "engine_name = 'sqlite:///' + database_name\n",
    "engine = create_engine(engine_name)\n",
    "df =pd.read_sql(\"SELECT * FROM messages_table\", engine)\n",
    "X = df['message']\n",
    "Y = df.drop(['id','message','original','genre'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    returns a tokenized, lemmatized and normalized version of text\n",
    "\n",
    "    Args:\n",
    "        text (str): input text to be tokenized, lemmatized and normalized \n",
    "    \n",
    "    Returns:\n",
    "        Tokenized, lemmatized and normalized version of text\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(y_actual, y_pred, measure):\n",
    "    \"\"\"\n",
    "    Creates a pretty print of the results of sklearns classification report comparing y_actual and y_pred\n",
    "\n",
    "    Args:\n",
    "        y_actual (dataframe): expected values\n",
    "        y_pred (dataframe): predicted values\n",
    "        measure (str): choice of measure ('weighted avg','micro avg','macro avg' )\n",
    "    \n",
    " \n",
    "    \"\"\"\n",
    "    print(\"\\t\\tWeighted Average Scores Over Each Output Class\\n\")\n",
    "    print(\"\\t\\tPrecision\\tRecall\\t\\tF1_Score\")\n",
    "    for column_name, column in y_actual.iteritems():\n",
    "        report  = classification_report(y_actual[column_name], y_pred[column_name], output_dict=True )\n",
    "        prec = report[measure]['precision']\n",
    "        recall =  report[measure]['recall']\n",
    "        f1 = report[measure]['f1-score']\n",
    "        print(\"%20.2f %15.2f % 15.2f\" % (prec, recall, f1) + \"\\t\\t\" + column_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a straighforward single tree model to make training tractable in terms of time\n",
    "DTC = DecisionTreeClassifier(random_state = 11)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(estimator=DTC))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19635,)\n",
      "(6545,)\n",
      "(19635, 36)\n",
      "(6545, 36)\n"
     ]
    }
   ],
   "source": [
    "#Split the input data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "#Check check that dataframes are of expected size\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14787</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24843</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16219</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      related request offer aid_related medical_help medical_products  \\\n",
       "800         1       1     0           1            0                1   \n",
       "14787       1       0     0           1            0                0   \n",
       "6430        0       0     0           0            0                0   \n",
       "24843       1       0     0           0            0                0   \n",
       "16219       1       0     0           1            0                0   \n",
       "\n",
       "      search_and_rescue security military child_alone  ... aid_centers  \\\n",
       "800                   0        0        0           0  ...           0   \n",
       "14787                 0        0        0           0  ...           0   \n",
       "6430                  0        0        0           0  ...           0   \n",
       "24843                 0        0        0           0  ...           0   \n",
       "16219                 0        0        0           0  ...           0   \n",
       "\n",
       "      other_infrastructure weather_related floods storm fire earthquake cold  \\\n",
       "800                      0               0      0     0    0          0    0   \n",
       "14787                    0               1      0     1    0          0    0   \n",
       "6430                     0               0      0     0    0          0    0   \n",
       "24843                    0               0      0     0    0          0    0   \n",
       "16219                    0               1      0     0    0          0    1   \n",
       "\n",
       "      other_weather direct_report  \n",
       "800               0             1  \n",
       "14787             0             0  \n",
       "6430              0             0  \n",
       "24843             0             0  \n",
       "16219             0             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...on_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best'),\n",
       "           n_jobs=None))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0      1.0      1.0    0.0          1.0           0.0               1.0   \n",
       "1      1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "2      1.0      0.0    0.0          1.0           0.0               0.0   \n",
       "3      1.0      0.0    0.0          1.0           1.0               0.0   \n",
       "4      1.0      0.0    0.0          1.0           0.0               0.0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "1                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "2                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "3                1.0       0.0       0.0          0.0  ...          0.0   \n",
       "4                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "1                   0.0              1.0     1.0    1.0   0.0         0.0   \n",
       "2                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "3                   0.0              1.0     0.0    0.0   0.0         0.0   \n",
       "4                   0.0              1.0     0.0    0.0   0.0         0.0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0   0.0            0.0            1.0  \n",
       "1   0.0            0.0            0.0  \n",
       "2   0.0            0.0            0.0  \n",
       "3   0.0            1.0            0.0  \n",
       "4   0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions with the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "#convert numpy output to dataframe and add columns\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df.columns = y_test.columns\n",
    "\n",
    "#Convert predictions and correct y values to float for faciliate comparison\n",
    "y_pred_df = y_pred_df.astype('float64')\n",
    "y_test = y_test.astype('float64')\n",
    "y_pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tWeighted Average Scores Over Each Output Class\n",
      "\n",
      "\t\tPrecision\tRecall\t\tF1_Score\n",
      "                0.74            0.74            0.74\t\trelated\n",
      "                0.85            0.86            0.85\t\trequest\n",
      "                0.99            0.99            0.99\t\toffer\n",
      "                0.70            0.70            0.70\t\taid_related\n",
      "                0.89            0.89            0.89\t\tmedical_help\n",
      "                0.94            0.94            0.94\t\tmedical_products\n",
      "                0.96            0.96            0.96\t\tsearch_and_rescue\n",
      "                0.97            0.97            0.97\t\tsecurity\n",
      "                0.96            0.96            0.96\t\tmilitary\n",
      "                1.00            1.00            1.00\t\tchild_alone\n",
      "                0.95            0.95            0.95\t\twater\n",
      "                0.93            0.94            0.93\t\tfood\n",
      "                0.94            0.94            0.94\t\tshelter\n",
      "                0.98            0.99            0.99\t\tclothing\n",
      "                0.97            0.97            0.97\t\tmoney\n",
      "                0.98            0.98            0.98\t\tmissing_people\n",
      "                0.95            0.96            0.95\t\trefugees\n",
      "                0.96            0.96            0.96\t\tdeath\n",
      "                0.81            0.82            0.81\t\tother_aid\n",
      "                0.90            0.90            0.90\t\tinfrastructure_related\n",
      "                0.93            0.94            0.93\t\ttransport\n",
      "                0.95            0.95            0.95\t\tbuildings\n",
      "                0.97            0.98            0.98\t\telectricity\n",
      "                0.99            0.99            0.99\t\ttools\n",
      "                0.98            0.98            0.98\t\thospitals\n",
      "                0.99            0.99            0.99\t\tshops\n",
      "                0.98            0.99            0.98\t\taid_centers\n",
      "                0.93            0.93            0.93\t\tother_infrastructure\n",
      "                0.84            0.84            0.84\t\tweather_related\n",
      "                0.93            0.93            0.93\t\tfloods\n",
      "                0.93            0.94            0.93\t\tstorm\n",
      "                0.99            0.99            0.99\t\tfire\n",
      "                0.96            0.96            0.96\t\tearthquake\n",
      "                0.98            0.98            0.98\t\tcold\n",
      "                0.92            0.92            0.92\t\tother_weather\n",
      "                0.81            0.81            0.81\t\tdirect_report\n"
     ]
    }
   ],
   "source": [
    "print_score(y_test, y_pred_df, 'weighted avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gridsearch to optimise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...on_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best'),\n",
       "           n_jobs=None))]),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'clf__estimator__criterion': ['gini', 'entropy'], 'clf__estimator__splitter': ['best', 'random'], 'clf__estimator__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000AEF0BCCC0>, 'clf__estimator__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000AEF0BC780>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'clf__estimator__criterion': [\"gini\", \"entropy\"],\n",
    "              'clf__estimator__splitter': [\"best\", \"random\"],\n",
    "              'clf__estimator__max_depth': randint(3, 6),\n",
    "              'clf__estimator__min_samples_split': randint(2,6)}\n",
    "\n",
    "#to faciliate easy experimentation, allow for reduced input data to gridsearch\n",
    "gridsearch_percent_of_dataset = 20\n",
    "\n",
    "#calculate reduced sample size according to 'gridsearch_percent_of_dataset'\n",
    "len_full_dataset = len(X_train)\n",
    "sample_size = int((len_full_dataset/100)*gridsearch_percent_of_dataset)\n",
    "\n",
    "grid_obj = RandomizedSearchCV(pipeline,parameters,n_iter=5, cv=5 )\n",
    "grid_obj.fit(X_train[:sample_size], y_train[:sample_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tWeighted Average Scores Over Each Output Class\n",
      "\n",
      "\t\tPrecision\tRecall\t\tF1_Score\n",
      "                0.71            0.76            0.68\t\trelated\n",
      "                0.85            0.86            0.83\t\trequest\n",
      "                0.99            1.00            0.99\t\toffer\n",
      "                0.69            0.67            0.63\t\taid_related\n",
      "                0.89            0.92            0.89\t\tmedical_help\n",
      "                0.95            0.95            0.94\t\tmedical_products\n",
      "                0.97            0.97            0.97\t\tsearch_and_rescue\n",
      "                0.97            0.98            0.97\t\tsecurity\n",
      "                0.96            0.97            0.96\t\tmilitary\n",
      "                1.00            1.00            1.00\t\tchild_alone\n",
      "                0.95            0.96            0.95\t\twater\n",
      "                0.95            0.95            0.95\t\tfood\n",
      "                0.94            0.95            0.94\t\tshelter\n",
      "                0.99            0.99            0.99\t\tclothing\n",
      "                0.97            0.98            0.97\t\tmoney\n",
      "                0.99            0.99            0.99\t\tmissing_people\n",
      "                0.96            0.97            0.96\t\trefugees\n",
      "                0.96            0.96            0.96\t\tdeath\n",
      "                0.83            0.87            0.82\t\tother_aid\n",
      "                0.91            0.94            0.92\t\tinfrastructure_related\n",
      "                0.95            0.96            0.95\t\ttransport\n",
      "                0.94            0.95            0.94\t\tbuildings\n",
      "                0.97            0.98            0.97\t\telectricity\n",
      "                0.99            0.99            0.99\t\ttools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\disaster_env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\disaster_env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\disaster_env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0.98            0.99            0.98\t\thospitals\n",
      "                0.99            0.99            0.99\t\tshops\n",
      "                0.98            0.99            0.99\t\taid_centers\n",
      "                0.93            0.96            0.94\t\tother_infrastructure\n",
      "                0.83            0.81            0.79\t\tweather_related\n",
      "                0.94            0.94            0.94\t\tfloods\n",
      "                0.93            0.94            0.93\t\tstorm\n",
      "                0.99            0.99            0.99\t\tfire\n",
      "                0.97            0.97            0.97\t\tearthquake\n",
      "                0.98            0.98            0.98\t\tcold\n",
      "                0.93            0.95            0.93\t\tother_weather\n",
      "                0.83            0.84            0.82\t\tdirect_report\n"
     ]
    }
   ],
   "source": [
    "#Retest after gridsearch\n",
    "\n",
    "optimised_classifier = grid_obj.best_estimator_\n",
    "#Refit the classifier\n",
    "optimised_classifier.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "# Make predictions and score using the optimised model\n",
    "predictions = optimised_classifier.predict(X_test)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.columns = y_test.columns\n",
    "predictions = predictions.astype('float64')\n",
    "\n",
    "print_score(y_test, predictions, 'weighted avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(optimised_classifier, open(output_model_file, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
